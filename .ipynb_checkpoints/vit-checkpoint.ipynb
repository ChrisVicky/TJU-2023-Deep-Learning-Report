{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets vit-pytorch torch Linformer torchvision matplotlib torch numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iYExLmKhnNG1"
   },
   "outputs": [],
   "source": [
    "from vit_pytorch.efficient import ViT\n",
    "import vit_pytorch\n",
    "from datasets import load_dataset\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from linformer import Linformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BwMaRC38fTLX",
    "outputId": "0bb6df4c-9dd1-4c65-942c-98eab31d4302"
   },
   "outputs": [],
   "source": [
    "print(\"Hello World\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oLJKm1ilKUdz"
   },
   "source": [
    "## LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kF5zw-Q4gXxs",
    "outputId": "8b784c0b-c96b-4ffa-b71a-b99e4aac631e"
   },
   "outputs": [],
   "source": [
    "# Load, split data\n",
    "food = load_dataset(\"food101\", split=\"train[:1000]\")\n",
    "food = food.train_test_split(test_size=0.2)\n",
    "# Map label ids with label names\n",
    "labels = food[\"test\"].features[\"label\"].names\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = str(i)\n",
    "    id2label[str(i)] = label\n",
    "print(f\"Train: {len(food['train'])}\")\n",
    "print(f\"Test: {len(food['test'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 16\n",
    "image_size = 256\n",
    "half_size = 112"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((half_size, half_size)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "        transforms.Resize((half_size, half_size)),\n",
    "        transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make my Special Input Matrix\n",
    "def mk_special_matrix(tmp):\n",
    "    ret = torch.cat([tmp[:,patch_size//2:,:], tmp[:,-patch_size//2:,:]], dim=1) # Cut the TOP half-patch-sized slice and cat to the BOTTOM\n",
    "    res = torch.cat([ret[:,:,-patch_size//2:], ret[:,:,patch_size//2:]], dim=2) # Cut the LEFT half-patch-sized slice and cat to the RIGHT\n",
    "    return res\n",
    "\n",
    "\n",
    "def mk_big_matrix(tmp, is_special=False):\n",
    "    \"\"\"\n",
    "        Make an (image_size x image_size) sized matrix that contains\n",
    "        is_special == FALSE)):\n",
    "            WHETHER contains a \n",
    "              2x2 Matrix of tmp /                 \\ \n",
    "                                | TMP      SPECIAL| \n",
    "                                |                 |\n",
    "                                | SPECIAL  TMP    |\n",
    "                                \\                 / 2x2\n",
    "        is_special == TRUE)):\n",
    "            OR      contains a\n",
    "                                /                 \\  \n",
    "                                | TMP      SPECIAL| \n",
    "                                |                 |\n",
    "                                | SPECIAL  TMP    |\n",
    "                                \\                 / 2x2                        \n",
    "    \"\"\"\n",
    "    special = tmp\n",
    "    if is_special:\n",
    "        special = mk_special_matrix(tmp)\n",
    "    up = torch.cat([tmp, special], dim=1)\n",
    "    down = torch.cat([special, tmp], dim=1)\n",
    "    big_matrix = torch.cat([up, down], dim=2)\n",
    "    return big_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal Train and Test Data\n",
    "train_data, test_data = dict(), dict()\n",
    "train_data[\"img\"] = [mk_big_matrix(train_transform(f)) for f in food[\"train\"][\"image\"]]\n",
    "train_data[\"label\"] = food[\"train\"][\"label\"]\n",
    "test_data[\"img\"] = [mk_big_matrix(test_transform(f)) for f in food[\"test\"][\"image\"]]\n",
    "test_data[\"label\"] = food[\"test\"][\"label\"]\n",
    "print(f\"INPUT SIZE: {train_data['img'][0].size()}\")\n",
    "print(f\"Train: {len(train_data['label'])}\")\n",
    "print(f\"Test: {len(test_data['label'])}\")\n",
    "\n",
    "# Special Train and Test Data\n",
    "train_data_S, test_data_S = dict(), dict()\n",
    "train_data_S[\"img\"] = [mk_big_matrix(train_transform(f), True) for f in food[\"train\"][\"image\"]]\n",
    "train_data_S[\"label\"] = food[\"train\"][\"label\"]\n",
    "test_data_S[\"img\"] = [mk_big_matrix(test_transform(f), True) for f in food[\"test\"][\"image\"]]\n",
    "test_data_S[\"label\"] = food[\"test\"][\"label\"]\n",
    "print(f\"INPUT SIZE: {train_data_S['img'][0].size()}\")\n",
    "print(f\"Train: {len(train_data_S['label'])}\")\n",
    "print(f\"Test: {len(test_data_S['label'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gKxCFycTK2r2"
   },
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 716
    },
    "id": "B2sC6sxOK1ox",
    "outputId": "71fcaf1e-c142-4847-e60f-340581d4c45f"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3,3,figsize=(16,12))\n",
    "for idx, ax in enumerate(axes.ravel()):\n",
    "    label = train_data[\"label\"][idx]\n",
    "    img = train_data[\"img\"][idx]\n",
    "    ax.set_title(id2label[str(label)])\n",
    "    image = transforms.ToPILImage()(img).convert('RGB')\n",
    "    ax.imshow(image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h37HsALvMeNw"
   },
   "source": [
    "## DataLoader Wrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l4uKQOKnM0MG"
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, File, transform=None):\n",
    "        self.File = File \n",
    "\n",
    "    # Get Current File Length\n",
    "    def __len__(self):\n",
    "        self.filelength=len(self.File['img'])\n",
    "        return self.filelength\n",
    "  \n",
    "    def __getitem__(self, idx):\n",
    "        label = self.File[\"label\"][idx]\n",
    "        img = self.File[\"img\"][idx]\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_my_data = MyDataset(train_data)\n",
    "test_my_data = MyDataset(test_data)\n",
    "train_my_data_S = MyDataset(train_data_S)\n",
    "test_my_data_S = MyDataset(test_data_S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ytbmeGMqN9LQ"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_my_data, batch_size = 15, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_my_data, batch_size = 15, shuffle=True)\n",
    "train_loader_S = DataLoader(dataset=train_my_data_S, batch_size = 15, shuffle=True)\n",
    "test_loader_S = DataLoader(dataset=test_my_data_S, batch_size = 15, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PjtQv4dpOSKY"
   },
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelDict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Phm5CvSqOU9G"
   },
   "outputs": [],
   "source": [
    "# Normal ViT Model\n",
    "efficient_transformer = Linformer(\n",
    "    dim=128,\n",
    "    seq_len=49+1,  # 7x7 patches + 1 cls-token\n",
    "    depth=12,\n",
    "    heads=8,\n",
    "    k=64,\n",
    ")\n",
    "model_vit_efficient = ViT(\n",
    "    dim=128,\n",
    "    image_size=image_size,\n",
    "    patch_size=patch_size,\n",
    "    num_classes=len(labels),\n",
    "    transformer=efficient_transformer,\n",
    "    channels=3,\n",
    ").to(device)\n",
    "# ModelDict[\"efficientViT\"] = model_vit_efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal ViT\n",
    "model_vit = vit_pytorch.ViT(\n",
    "    dim=128,\n",
    "    image_size=image_size,\n",
    "    patch_size=patch_size,\n",
    "    num_classes=len(labels),\n",
    "    depth=12,\n",
    "    heads=8,\n",
    "    mlp_dim=128,\n",
    ").to(device)\n",
    "ModelDict[\"ViT\"] = model_vit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Vit\n",
    "from vit_pytorch.deepvit import DeepViT\n",
    "model_deepvit = DeepViT(\n",
    "    image_size = image_size,\n",
    "    patch_size = patch_size,\n",
    "    num_classes = len(labels),\n",
    "    dim = 128,\n",
    "    depth = 12,\n",
    "    heads = 8,\n",
    "    mlp_dim = 128,\n",
    ")\n",
    "# ModelDict[\"Deepvit\"] = model_deepvit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CaiT Model\n",
    "from vit_pytorch.cait import CaiT\n",
    "model_cait = CaiT(\n",
    "    image_size = image_size,\n",
    "    patch_size = patch_size,\n",
    "    num_classes = len(labels),\n",
    "    dim = 128,\n",
    "    depth = 12,             # depth of transformer for patch to patch attention only\n",
    "    cls_depth = 2,          # depth of cross attention of CLS tokens to patch\n",
    "    heads = 8,\n",
    "    mlp_dim = 128,\n",
    ")\n",
    "ModelDict[\"cait\"] = model_cait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MlOPXPmuPNtC"
   },
   "source": [
    "##  Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "id": "GXy_0_cNPe-C",
    "outputId": "8ed0d722-f26b-4011-90b4-c0c4c71d6c20"
   },
   "outputs": [],
   "source": [
    "def trainit(model, train_loader, test_loader, name=\"DefaultName\",lr=3e-5,EPOCH=30):\n",
    "    \"\"\"\n",
    "        Train Model on dataset\n",
    "            INPUT: \n",
    "                - model:           Defined model\n",
    "                - train_loader:    training data     ->  DataLoader(MyDataset, batchSize, Shutffled)\n",
    "                - test_loader:     test data         ->  DataLoader(MyDataset, batchSize, Shutffled)\n",
    "                - name:            Name of the model ->  (default \"DefaultName\")\n",
    "                - lr:              Learning Reate    ->  (default 1e-5)\n",
    "                - EPOCH:           Total Epoches     ->  (default 10) \n",
    "            OUTPUT: \n",
    "                - model:           After Training \n",
    "                - val_loss_list:   Validation Loss respect to Epoch \n",
    "                - train_loss_list: Training Loss respect to Epoch\n",
    "    \"\"\"\n",
    "    criterio = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    train_loss_list = []\n",
    "    val_loss_list = []\n",
    "    for epoch in range(EPOCH):\n",
    "        epoch_loss = 0\n",
    "        epoch_accuracy = 0\n",
    "        i = 0\n",
    "        for data, label in train_loader:\n",
    "            i += 1\n",
    "            data = data.to(device)\n",
    "            label = label.to(device) \n",
    "            output = model(data) \n",
    "            loss = criterio(output, label) \n",
    "\n",
    "            optimizer.zero_grad() \n",
    "            loss.backward() \n",
    "            optimizer.step() \n",
    "\n",
    "            acc = (output.argmax(dim=1)==label).float().mean() \n",
    "            epoch_accuracy += acc / len(train_loader)\n",
    "            epoch_loss += loss / len(train_loader) \n",
    "            print(f\"Epoch: {epoch}, {i}/{len(train_loader)} | Acc: {epoch_accuracy:.4f} | Los: {epoch_loss:.4f}\", end='\\r')\n",
    "        with torch.no_grad(): \n",
    "            epoch_val_acc = 0 \n",
    "            epoch_val_loss = 0\n",
    "            for data, label in test_loader:\n",
    "                data = data.to(device)\n",
    "                label = label.to(device)\n",
    "                val_output = model(data)\n",
    "                val_loss = criterio(val_output, label) \n",
    "                acc = (val_output.argmax(dim=1)==label).float().mean() \n",
    "                epoch_val_acc += acc / len(test_loader)\n",
    "                epoch_val_loss += val_loss / len(test_loader)\n",
    "        val_loss_list.append(epoch_val_loss)\n",
    "        train_loss_list.append(epoch_loss)\n",
    "        print(f\"{name:15s} > Epoch: {epoch+1:2d} | Loss: {epoch_loss:.4f} | acc: {epoch_accuracy:4f} | val_loss: {epoch_val_loss: .4f} | val_acc: {epoch_val_acc: .4f}\")\n",
    "        return model, train_loss_list, val_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in ModelDict:\n",
    "    print(f\"{key} ->\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainLossDict, ValLossDict, ModelOK = dict(), dict(), dict()\n",
    "for key in ModelDict:\n",
    "    print(key)\n",
    "    ModelOK[key], TrainLossDict[key], ValLossDict[key] = trainit(ModelDict[key], train_loader, test_loader, key, EPOCH=2)\n",
    "key = \"ViT_INPUTVARY\"\n",
    "ModelOK[key], TrainLossDict[key], ValLossDict[key] = trainit(ModelDict[key], train_loader_S, test_loader_S, key, EPOCH=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
